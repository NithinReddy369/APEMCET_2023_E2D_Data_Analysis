{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f057a409",
   "metadata": {},
   "source": [
    "# PDF to CSV Converter for APEMCET Data\n",
    "\n",
    "This notebook converts the APEMCET (AP Engineering Common Entrance Test) cutoff data from PDF format to CSV. It uses the following libraries:\n",
    "- `pdfplumber`: For extracting tables from PDF\n",
    "- `pandas`: For data manipulation and CSV output\n",
    "- `os`: For file path handling\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0a8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de18072",
   "metadata": {},
   "source": [
    "## File Path Configuration\n",
    "\n",
    "Define the input PDF file path and output CSV file path. We'll use the current directory to make it easier to work with relative paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9f348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file path: d:\\Projects\\APEMCET_2023\\APEAPCET_2022_Cutoff.pdf\n",
      "CSV file path: d:\\Projects\\APEMCET_2023\\csv_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "# Define input and output paths\n",
    "pdf_path = os.path.join(current_dir, \"APEAPCET_2022_Cutoff.pdf\")\n",
    "csv_path = os.path.join(current_dir, \"csv_file.csv\")\n",
    "\n",
    "print(f\"PDF file path: {pdf_path}\")\n",
    "print(f\"CSV file path: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b678d1",
   "metadata": {},
   "source": [
    "## Define Table Extraction Function\n",
    "\n",
    "Create a function to extract tables from the PDF file. This function will:\n",
    "1. Open the PDF file\n",
    "2. Process each page\n",
    "3. Extract tables from each page\n",
    "4. Convert tables to pandas DataFrames\n",
    "5. Combine all tables\n",
    "6. Save the result to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_from_pdf(pdf_path, csv_path):\n",
    "    \"\"\"\n",
    "    Extract tables from PDF and save them to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file\n",
    "        csv_path (str): Path where the CSV file will be saved\n",
    "    \"\"\"\n",
    "    # Check if the PDF file exists\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "    \n",
    "    # List to store all tables\n",
    "    all_tables = []\n",
    "    \n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Iterate through all pages\n",
    "            for page_number, page in enumerate(pdf.pages, 1):\n",
    "                print(f\"Processing page {page_number} of {len(pdf.pages)}\")\n",
    "                \n",
    "                # Extract tables from the current page\n",
    "                tables = page.extract_tables()\n",
    "                \n",
    "                # Process each table in the page\n",
    "                for table_number, table in enumerate(tables, 1):\n",
    "                    print(f\"Found table {table_number} on page {page_number}\")\n",
    "                    \n",
    "                    # Convert table to pandas DataFrame\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                    \n",
    "                    # Clean the DataFrame\n",
    "                    # Remove any empty rows\n",
    "                    df = df.dropna(how='all')\n",
    "                    # Remove any empty columns\n",
    "                    df = df.dropna(axis=1, how='all')\n",
    "                    \n",
    "                    all_tables.append(df)\n",
    "    \n",
    "        if not all_tables:\n",
    "            print(\"No tables found in the PDF\")\n",
    "            return\n",
    "        \n",
    "        # Combine all tables\n",
    "        final_df = pd.concat(all_tables, ignore_index=True)\n",
    "        \n",
    "        # Save to CSV\n",
    "        final_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Successfully saved data to {csv_path}\")\n",
    "        \n",
    "        # Display first few rows of the extracted data\n",
    "        print(\"\\nFirst few rows of the extracted data:\")\n",
    "        print(final_df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2961b0",
   "metadata": {},
   "source": [
    "## Run the Conversion\n",
    "\n",
    "Now let's run the function to convert the PDF to CSV. This will process all pages in the PDF and save the extracted tables to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee113b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1 of 60\n",
      "Found table 1 on page 1\n",
      "Processing page 2 of 60\n",
      "Found table 1 on page 1\n",
      "Processing page 2 of 60\n",
      "Found table 1 on page 2\n",
      "Processing page 3 of 60\n",
      "Found table 1 on page 2\n",
      "Processing page 3 of 60\n",
      "Found table 1 on page 3\n",
      "Processing page 4 of 60\n",
      "Found table 1 on page 3\n",
      "Processing page 4 of 60\n",
      "Found table 1 on page 4\n",
      "Processing page 5 of 60\n",
      "Found table 1 on page 4\n",
      "Processing page 5 of 60\n",
      "Found table 1 on page 5\n",
      "Processing page 6 of 60\n",
      "Found table 1 on page 5\n",
      "Processing page 6 of 60\n",
      "Found table 1 on page 6\n",
      "Processing page 7 of 60\n",
      "Found table 1 on page 6\n",
      "Processing page 7 of 60\n",
      "Found table 1 on page 7\n",
      "Processing page 8 of 60\n",
      "Found table 1 on page 7\n",
      "Processing page 8 of 60\n",
      "Found table 1 on page 8\n",
      "Processing page 9 of 60\n",
      "Found table 1 on page 8\n",
      "Processing page 9 of 60\n",
      "Found table 1 on page 9\n",
      "Processing page 10 of 60\n",
      "Found table 1 on page 9\n",
      "Processing page 10 of 60\n",
      "Found table 1 on page 10\n",
      "Processing page 11 of 60\n",
      "Found table 1 on page 10\n",
      "Processing page 11 of 60\n",
      "Found table 1 on page 11\n",
      "Processing page 12 of 60\n",
      "Found table 1 on page 11\n",
      "Processing page 12 of 60\n",
      "Found table 1 on page 12\n",
      "Processing page 13 of 60\n",
      "Found table 1 on page 12\n",
      "Processing page 13 of 60\n",
      "Found table 1 on page 13\n",
      "Processing page 14 of 60\n",
      "Found table 1 on page 13\n",
      "Processing page 14 of 60\n",
      "Found table 1 on page 14\n",
      "Processing page 15 of 60\n",
      "Found table 1 on page 14\n",
      "Processing page 15 of 60\n",
      "Found table 1 on page 15\n",
      "Processing page 16 of 60\n",
      "Found table 1 on page 15\n",
      "Processing page 16 of 60\n",
      "Found table 1 on page 16\n",
      "Processing page 17 of 60\n",
      "Found table 1 on page 16\n",
      "Processing page 17 of 60\n",
      "Found table 1 on page 17\n",
      "Processing page 18 of 60\n",
      "Found table 1 on page 17\n",
      "Processing page 18 of 60\n",
      "Found table 1 on page 18\n",
      "Processing page 19 of 60\n",
      "Found table 1 on page 18\n",
      "Processing page 19 of 60\n",
      "Found table 1 on page 19\n",
      "Processing page 20 of 60\n",
      "Found table 1 on page 19\n",
      "Processing page 20 of 60\n",
      "Found table 1 on page 20\n",
      "Processing page 21 of 60\n",
      "Found table 1 on page 20\n",
      "Processing page 21 of 60\n",
      "Found table 1 on page 21\n",
      "Processing page 22 of 60\n",
      "Found table 1 on page 21\n",
      "Processing page 22 of 60\n",
      "Found table 1 on page 22\n",
      "Processing page 23 of 60\n",
      "Found table 1 on page 22\n",
      "Processing page 23 of 60\n",
      "Found table 1 on page 23\n",
      "Processing page 24 of 60\n",
      "Found table 1 on page 23\n",
      "Processing page 24 of 60\n",
      "Found table 1 on page 24\n",
      "Processing page 25 of 60\n",
      "Found table 1 on page 24\n",
      "Processing page 25 of 60\n",
      "Found table 1 on page 25\n",
      "Processing page 26 of 60\n",
      "Found table 1 on page 25\n",
      "Processing page 26 of 60\n",
      "Found table 1 on page 26\n",
      "Processing page 27 of 60\n",
      "Found table 1 on page 26\n",
      "Processing page 27 of 60\n",
      "Found table 1 on page 27\n",
      "Processing page 28 of 60\n",
      "Found table 1 on page 27\n",
      "Processing page 28 of 60\n",
      "Found table 1 on page 28\n",
      "Processing page 29 of 60\n",
      "Found table 1 on page 28\n",
      "Processing page 29 of 60\n",
      "Found table 1 on page 29\n",
      "Processing page 30 of 60\n",
      "Found table 1 on page 29\n",
      "Processing page 30 of 60\n",
      "Found table 1 on page 30\n",
      "Processing page 31 of 60\n",
      "Found table 1 on page 30\n",
      "Processing page 31 of 60\n",
      "Found table 1 on page 31\n",
      "Processing page 32 of 60\n",
      "Found table 1 on page 31\n",
      "Processing page 32 of 60\n",
      "Found table 1 on page 32\n",
      "Processing page 33 of 60\n",
      "Found table 1 on page 32\n",
      "Processing page 33 of 60\n",
      "Found table 1 on page 33\n",
      "Processing page 34 of 60\n",
      "Found table 1 on page 33\n",
      "Processing page 34 of 60\n",
      "Found table 1 on page 34\n",
      "Processing page 35 of 60\n",
      "Found table 1 on page 34\n",
      "Processing page 35 of 60\n",
      "Found table 1 on page 35\n",
      "Processing page 36 of 60\n",
      "Found table 1 on page 35\n",
      "Processing page 36 of 60\n",
      "Found table 1 on page 36\n",
      "Processing page 37 of 60\n",
      "Found table 1 on page 36\n",
      "Processing page 37 of 60\n",
      "Found table 1 on page 37\n",
      "Processing page 38 of 60\n",
      "Found table 1 on page 37\n",
      "Processing page 38 of 60\n",
      "Found table 1 on page 38\n",
      "Processing page 39 of 60\n",
      "Found table 1 on page 38\n",
      "Processing page 39 of 60\n",
      "Found table 1 on page 39\n",
      "Processing page 40 of 60\n",
      "Found table 1 on page 39\n",
      "Processing page 40 of 60\n",
      "Found table 1 on page 40\n",
      "Processing page 41 of 60\n",
      "Found table 1 on page 40\n",
      "Processing page 41 of 60\n",
      "Found table 1 on page 41\n",
      "Processing page 42 of 60\n",
      "Found table 1 on page 41\n",
      "Processing page 42 of 60\n",
      "Found table 1 on page 42\n",
      "Processing page 43 of 60\n",
      "Found table 1 on page 42\n",
      "Processing page 43 of 60\n",
      "Found table 1 on page 43\n",
      "Processing page 44 of 60\n",
      "Found table 1 on page 43\n",
      "Processing page 44 of 60\n",
      "Found table 1 on page 44\n",
      "Processing page 45 of 60\n",
      "Found table 1 on page 44\n",
      "Processing page 45 of 60\n",
      "Found table 1 on page 45\n",
      "Processing page 46 of 60\n",
      "Found table 1 on page 45\n",
      "Processing page 46 of 60\n",
      "Found table 1 on page 46\n",
      "Processing page 47 of 60\n",
      "Found table 1 on page 46\n",
      "Processing page 47 of 60\n",
      "Found table 1 on page 47\n",
      "Processing page 48 of 60\n",
      "Found table 1 on page 47\n",
      "Processing page 48 of 60\n",
      "Found table 1 on page 48\n",
      "Processing page 49 of 60\n",
      "Found table 1 on page 48\n",
      "Processing page 49 of 60\n",
      "Found table 1 on page 49\n",
      "Processing page 50 of 60\n",
      "Found table 1 on page 49\n",
      "Processing page 50 of 60\n",
      "Found table 1 on page 50\n",
      "Processing page 51 of 60\n",
      "Found table 1 on page 50\n",
      "Processing page 51 of 60\n",
      "Found table 1 on page 51\n",
      "Processing page 52 of 60\n",
      "Found table 1 on page 51\n",
      "Processing page 52 of 60\n",
      "Found table 1 on page 52\n",
      "Processing page 53 of 60\n",
      "Found table 1 on page 52\n",
      "Processing page 53 of 60\n",
      "Found table 1 on page 53\n",
      "Processing page 54 of 60\n",
      "Found table 1 on page 53\n",
      "Processing page 54 of 60\n",
      "Found table 1 on page 54\n",
      "Processing page 55 of 60\n",
      "Found table 1 on page 54\n",
      "Processing page 55 of 60\n",
      "Found table 1 on page 55\n",
      "Processing page 56 of 60\n",
      "Found table 1 on page 55\n",
      "Processing page 56 of 60\n",
      "Found table 1 on page 56\n",
      "Processing page 57 of 60\n",
      "Found table 1 on page 56\n",
      "Processing page 57 of 60\n",
      "Found table 1 on page 57\n",
      "Found table 2 on page 57\n",
      "Processing page 58 of 60\n",
      "Found table 1 on page 57\n",
      "Found table 2 on page 57\n",
      "Processing page 58 of 60\n",
      "Found table 1 on page 58\n",
      "Processing page 59 of 60\n",
      "Found table 1 on page 58\n",
      "Processing page 59 of 60\n",
      "Found table 1 on page 59\n",
      "Processing page 60 of 60\n",
      "Found table 1 on page 59\n",
      "Processing page 60 of 60\n",
      "Found table 1 on page 60\n",
      "Successfully saved data to d:\\Projects\\APEMCET_2023\\csv_file.csv\n",
      "\n",
      "First few rows of the extracted data:\n",
      "  SNO inst_code                      inst_name type INST\\n_RE\\nG. DIST  \\\n",
      "0   1      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "1   2      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "2   3      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "3   4      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "4   5      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "\n",
      "        PLACE  COED AFFLIA\\n.UNIV  ESTD  ... BCC_B\\nOYS BCC_GI\\nRLS  \\\n",
      "0  GOLLAPROLU  COED         JNTUK  2008  ...     143031      143031   \n",
      "1  GOLLAPROLU  COED         JNTUK  2008  ...     132938      139146   \n",
      "2  GOLLAPROLU  COED         JNTUK  2008  ...     114459      114459   \n",
      "3  GOLLAPROLU  COED         JNTUK  2008  ...                          \n",
      "4  GOLLAPROLU  COED         JNTUK  2008  ...                 169131   \n",
      "\n",
      "  BCD_B\\nOYS BCD_GI\\nRLS BCE_B\\nOYS BCE_GI\\nRLS OC_EWS_B\\nOYS OC_EWS_GI\\nRLS  \\\n",
      "0     143031      143031     143031      143031        158522                  \n",
      "1     134908      157283     144114      144114        149718         120842   \n",
      "2     114459      146246     114459      114459        128288                  \n",
      "3     169142      169163     169163      169163                                \n",
      "4     169142      169142     169163      169163                                \n",
      "\n",
      "  COLLFEE Local\\narea  \n",
      "0   35000         NaN  \n",
      "1   35000         NaN  \n",
      "2   35000         NaN  \n",
      "3   35000         NaN  \n",
      "4   35000         NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Found table 1 on page 60\n",
      "Successfully saved data to d:\\Projects\\APEMCET_2023\\csv_file.csv\n",
      "\n",
      "First few rows of the extracted data:\n",
      "  SNO inst_code                      inst_name type INST\\n_RE\\nG. DIST  \\\n",
      "0   1      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "1   2      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "2   3      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "3   4      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "4   5      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
      "\n",
      "        PLACE  COED AFFLIA\\n.UNIV  ESTD  ... BCC_B\\nOYS BCC_GI\\nRLS  \\\n",
      "0  GOLLAPROLU  COED         JNTUK  2008  ...     143031      143031   \n",
      "1  GOLLAPROLU  COED         JNTUK  2008  ...     132938      139146   \n",
      "2  GOLLAPROLU  COED         JNTUK  2008  ...     114459      114459   \n",
      "3  GOLLAPROLU  COED         JNTUK  2008  ...                          \n",
      "4  GOLLAPROLU  COED         JNTUK  2008  ...                 169131   \n",
      "\n",
      "  BCD_B\\nOYS BCD_GI\\nRLS BCE_B\\nOYS BCE_GI\\nRLS OC_EWS_B\\nOYS OC_EWS_GI\\nRLS  \\\n",
      "0     143031      143031     143031      143031        158522                  \n",
      "1     134908      157283     144114      144114        149718         120842   \n",
      "2     114459      146246     114459      114459        128288                  \n",
      "3     169142      169163     169163      169163                                \n",
      "4     169142      169142     169163      169163                                \n",
      "\n",
      "  COLLFEE Local\\narea  \n",
      "0   35000         NaN  \n",
      "1   35000         NaN  \n",
      "2   35000         NaN  \n",
      "3   35000         NaN  \n",
      "4   35000         NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract tables and save to CSV\n",
    "extract_tables_from_pdf(pdf_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058193e",
   "metadata": {},
   "source": [
    "## Preview the Results\n",
    "\n",
    "Let's read the generated CSV file and display the first few rows to verify the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9017aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file shape: (1504, 32)\n",
      "\n",
      "Columns in the CSV file:\n",
      "['SNO', 'inst_code', 'inst_name', 'type', 'INST\\n_RE\\nG.', 'DIST', 'PLACE', 'COED', 'AFFLIA\\n.UNIV', 'ESTD', 'branch_\\ncode', 'Local_Ar\\nea', 'OC_BO\\nYS', 'OC_GIR\\nLS', 'SC_BO\\nYS', 'SC_GIR\\nLS', 'ST_BOY\\nS', 'ST_GIR\\nLS', 'BCA_B\\nOYS', 'BCA_GI\\nRLS', 'BCB_B\\nOYS', 'BCB_GI\\nRLS', 'BCC_B\\nOYS', 'BCC_GI\\nRLS', 'BCD_B\\nOYS', 'BCD_GI\\nRLS', 'BCE_B\\nOYS', 'BCE_GI\\nRLS', 'OC_EWS_B\\nOYS', 'OC_EWS_GI\\nRLS', 'COLLFEE', 'Local\\narea']\n",
      "\n",
      "First few rows of the data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SNO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inst_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "inst_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "INST\n_RE\nG.",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DIST",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PLACE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COED",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AFFLIA\n.UNIV",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ESTD",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "branch_\ncode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Local_Ar\nea",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "OC_BO\nYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OC_GIR\nLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SC_BO\nYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SC_GIR\nLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST_BOY\nS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST_GIR\nLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCA_B\nOYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCA_GI\nRLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCB_B\nOYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCB_GI\nRLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCC_B\nOYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCC_GI\nRLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCD_B\nOYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCD_GI\nRLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCE_B\nOYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BCE_GI\nRLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OC_EWS_B\nOYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OC_EWS_GI\nRLS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "COLLFEE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Local\narea",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "97ae70c0-02f3-4ad1-86d4-d2c709c3c844",
       "rows": [
        [
         "0",
         "1.0",
         "ACEE",
         "ADARSH COLLEGE OF ENGINEERING",
         "PVT",
         "AU",
         "EG",
         "GOLLAPROLU",
         "COED",
         "JNTUK",
         "2008",
         "CIV",
         null,
         "143031.0",
         "143031.0",
         "170697.0",
         "170697.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "143031.0",
         "158522.0",
         null,
         "35000.0",
         null
        ],
        [
         "1",
         "2.0",
         "ACEE",
         "ADARSH COLLEGE OF ENGINEERING",
         "PVT",
         "AU",
         "EG",
         "GOLLAPROLU",
         "COED",
         "JNTUK",
         "2008",
         "CSE",
         null,
         "132938.0",
         "132938.0",
         "170635.0",
         "170635.0",
         "173467.0",
         "173467.0",
         "153425.0",
         "167840.0",
         "167292.0",
         "169169.0",
         "132938.0",
         "139146.0",
         "134908.0",
         "157283.0",
         "144114.0",
         "144114.0",
         "149718.0",
         "120842.0",
         "35000.0",
         null
        ],
        [
         "2",
         "3.0",
         "ACEE",
         "ADARSH COLLEGE OF ENGINEERING",
         "PVT",
         "AU",
         "EG",
         "GOLLAPROLU",
         "COED",
         "JNTUK",
         "2008",
         "ECE",
         null,
         "114459.0",
         "114459.0",
         "114459.0",
         "114459.0",
         "114459.0",
         "114459.0",
         "165041.0",
         "165041.0",
         "163503.0",
         "163503.0",
         "114459.0",
         "114459.0",
         "114459.0",
         "146246.0",
         "114459.0",
         "114459.0",
         "128288.0",
         null,
         "35000.0",
         null
        ],
        [
         "3",
         "4.0",
         "ACEE",
         "ADARSH COLLEGE OF ENGINEERING",
         "PVT",
         "AU",
         "EG",
         "GOLLAPROLU",
         "COED",
         "JNTUK",
         "2008",
         "EEE",
         null,
         "169131.0",
         "169163.0",
         "169131.0",
         "169163.0",
         "173554.0",
         "173554.0",
         "169163.0",
         "169163.0",
         "169169.0",
         "169169.0",
         null,
         null,
         "169142.0",
         "169163.0",
         "169163.0",
         "169163.0",
         null,
         null,
         "35000.0",
         null
        ],
        [
         "4",
         "5.0",
         "ACEE",
         "ADARSH COLLEGE OF ENGINEERING",
         "PVT",
         "AU",
         "EG",
         "GOLLAPROLU",
         "COED",
         "JNTUK",
         "2008",
         "MEC",
         null,
         "169131.0",
         "169131.0",
         "173540.0",
         "173540.0",
         "169131.0",
         "169131.0",
         "169163.0",
         "169163.0",
         "169169.0",
         "169169.0",
         null,
         "169131.0",
         "169142.0",
         "169142.0",
         "169163.0",
         "169163.0",
         null,
         null,
         "35000.0",
         null
        ]
       ],
       "shape": {
        "columns": 32,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNO</th>\n",
       "      <th>inst_code</th>\n",
       "      <th>inst_name</th>\n",
       "      <th>type</th>\n",
       "      <th>INST\\n_RE\\nG.</th>\n",
       "      <th>DIST</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>COED</th>\n",
       "      <th>AFFLIA\\n.UNIV</th>\n",
       "      <th>ESTD</th>\n",
       "      <th>...</th>\n",
       "      <th>BCC_B\\nOYS</th>\n",
       "      <th>BCC_GI\\nRLS</th>\n",
       "      <th>BCD_B\\nOYS</th>\n",
       "      <th>BCD_GI\\nRLS</th>\n",
       "      <th>BCE_B\\nOYS</th>\n",
       "      <th>BCE_GI\\nRLS</th>\n",
       "      <th>OC_EWS_B\\nOYS</th>\n",
       "      <th>OC_EWS_GI\\nRLS</th>\n",
       "      <th>COLLFEE</th>\n",
       "      <th>Local\\narea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ACEE</td>\n",
       "      <td>ADARSH COLLEGE OF ENGINEERING</td>\n",
       "      <td>PVT</td>\n",
       "      <td>AU</td>\n",
       "      <td>EG</td>\n",
       "      <td>GOLLAPROLU</td>\n",
       "      <td>COED</td>\n",
       "      <td>JNTUK</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>143031.0</td>\n",
       "      <td>143031.0</td>\n",
       "      <td>143031.0</td>\n",
       "      <td>143031.0</td>\n",
       "      <td>143031.0</td>\n",
       "      <td>143031.0</td>\n",
       "      <td>158522.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ACEE</td>\n",
       "      <td>ADARSH COLLEGE OF ENGINEERING</td>\n",
       "      <td>PVT</td>\n",
       "      <td>AU</td>\n",
       "      <td>EG</td>\n",
       "      <td>GOLLAPROLU</td>\n",
       "      <td>COED</td>\n",
       "      <td>JNTUK</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>132938.0</td>\n",
       "      <td>139146.0</td>\n",
       "      <td>134908.0</td>\n",
       "      <td>157283.0</td>\n",
       "      <td>144114.0</td>\n",
       "      <td>144114.0</td>\n",
       "      <td>149718.0</td>\n",
       "      <td>120842.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>ACEE</td>\n",
       "      <td>ADARSH COLLEGE OF ENGINEERING</td>\n",
       "      <td>PVT</td>\n",
       "      <td>AU</td>\n",
       "      <td>EG</td>\n",
       "      <td>GOLLAPROLU</td>\n",
       "      <td>COED</td>\n",
       "      <td>JNTUK</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>114459.0</td>\n",
       "      <td>114459.0</td>\n",
       "      <td>114459.0</td>\n",
       "      <td>146246.0</td>\n",
       "      <td>114459.0</td>\n",
       "      <td>114459.0</td>\n",
       "      <td>128288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ACEE</td>\n",
       "      <td>ADARSH COLLEGE OF ENGINEERING</td>\n",
       "      <td>PVT</td>\n",
       "      <td>AU</td>\n",
       "      <td>EG</td>\n",
       "      <td>GOLLAPROLU</td>\n",
       "      <td>COED</td>\n",
       "      <td>JNTUK</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169142.0</td>\n",
       "      <td>169163.0</td>\n",
       "      <td>169163.0</td>\n",
       "      <td>169163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ACEE</td>\n",
       "      <td>ADARSH COLLEGE OF ENGINEERING</td>\n",
       "      <td>PVT</td>\n",
       "      <td>AU</td>\n",
       "      <td>EG</td>\n",
       "      <td>GOLLAPROLU</td>\n",
       "      <td>COED</td>\n",
       "      <td>JNTUK</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169131.0</td>\n",
       "      <td>169142.0</td>\n",
       "      <td>169142.0</td>\n",
       "      <td>169163.0</td>\n",
       "      <td>169163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNO inst_code                      inst_name type INST\\n_RE\\nG. DIST  \\\n",
       "0  1.0      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
       "1  2.0      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
       "2  3.0      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
       "3  4.0      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
       "4  5.0      ACEE  ADARSH COLLEGE OF ENGINEERING  PVT            AU   EG   \n",
       "\n",
       "        PLACE  COED AFFLIA\\n.UNIV  ESTD  ... BCC_B\\nOYS BCC_GI\\nRLS  \\\n",
       "0  GOLLAPROLU  COED         JNTUK  2008  ...   143031.0    143031.0   \n",
       "1  GOLLAPROLU  COED         JNTUK  2008  ...   132938.0    139146.0   \n",
       "2  GOLLAPROLU  COED         JNTUK  2008  ...   114459.0    114459.0   \n",
       "3  GOLLAPROLU  COED         JNTUK  2008  ...        NaN         NaN   \n",
       "4  GOLLAPROLU  COED         JNTUK  2008  ...        NaN    169131.0   \n",
       "\n",
       "   BCD_B\\nOYS  BCD_GI\\nRLS  BCE_B\\nOYS  BCE_GI\\nRLS  OC_EWS_B\\nOYS  \\\n",
       "0    143031.0     143031.0    143031.0     143031.0       158522.0   \n",
       "1    134908.0     157283.0    144114.0     144114.0       149718.0   \n",
       "2    114459.0     146246.0    114459.0     114459.0       128288.0   \n",
       "3    169142.0     169163.0    169163.0     169163.0            NaN   \n",
       "4    169142.0     169142.0    169163.0     169163.0            NaN   \n",
       "\n",
       "   OC_EWS_GI\\nRLS  COLLFEE  Local\\narea  \n",
       "0             NaN  35000.0          NaN  \n",
       "1        120842.0  35000.0          NaN  \n",
       "2             NaN  35000.0          NaN  \n",
       "3             NaN  35000.0          NaN  \n",
       "4             NaN  35000.0          NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and display the first few rows of the generated CSV file\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV file shape:\", df.shape)\n",
    "    print(\"\\nColumns in the CSV file:\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\nFirst few rows of the data:\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
